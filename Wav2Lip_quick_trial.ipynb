{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copie de Wav2Lip_quick_trial.ipynb","provenance":[{"file_id":"1tZpDWXz49W6wDcTprANRGLo2D_EbD5J8","timestamp":1608297715967},{"file_id":"1NLUwupCBsB1HrpEmOIHeMgU63sus2LxP","timestamp":1597735440478}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vSQFs_G8caeE"},"source":["# Collab preliminaries"]},{"cell_type":"code","metadata":{"id":"XIVB0Xn1g6ih","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608315443894,"user_tz":-60,"elapsed":1229,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"af3db94f-57c5-4d86-8520-a555d23b38ac"},"source":["!nvcc --version"],"execution_count":1,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2019 NVIDIA Corporation\n","Built on Sun_Jul_28_19:07:16_PDT_2019\n","Cuda compilation tools, release 10.1, V10.1.243\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qciH4PsUazL_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608315463875,"user_tz":-60,"elapsed":19501,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"6ce2de66-051b-4d34-866b-bd845a274be9"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yJ5taGmPcWV-"},"source":["# Get the code and models"]},{"cell_type":"code","metadata":{"id":"P3LihClHbUd3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608315467475,"user_tz":-60,"elapsed":2150,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"0fc24e3d-c305-45af-b1fb-5c36d153436f"},"source":["!git clone https://github.com/Rudrabha/Wav2Lip.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'Wav2Lip'...\n","remote: Enumerating objects: 65, done.\u001b[K\n","remote: Counting objects: 100% (65/65), done.\u001b[K\n","remote: Compressing objects: 100% (65/65), done.\u001b[K\n","remote: Total 311 (delta 31), reused 7 (delta 0), pack-reused 246\u001b[K\n","Receiving objects: 100% (311/311), 503.21 KiB | 6.45 MiB/s, done.\n","Resolving deltas: 100% (159/159), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y-19nzx8SamJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608315469896,"user_tz":-60,"elapsed":1163,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"9537d495-bda8-4159-98fa-83567f8d234b"},"source":["!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["gdrive\tsample_data  Wav2Lip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4gyCrjwHcqO_","executionInfo":{"status":"ok","timestamp":1608315482682,"user_tz":-60,"elapsed":10603,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"ac31266f-5dc1-4cc4-a46a-635419783c2a"},"source":["import shutil\r\n","shutil.copy2(\"/content/gdrive/My Drive/Colab Notebooks/Deep/wav2lip_gan.pth\", '/content/Wav2Lip/checkpoints')"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/Wav2Lip/checkpoints/wav2lip_gan.pth'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"aWTaOS3ncFt6"},"source":["# Get the pre-requisites"]},{"cell_type":"code","metadata":{"id":"Ooh28vw-Uvd3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608315516166,"user_tz":-60,"elapsed":31033,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"94278c0c-2911-41e5-9146-2b58d6701a6c"},"source":["!pip uninstall tensorflow tensorflow-gpu"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.4.0:\n","  Would remove:\n","    /usr/local/bin/estimator_ckpt_converter\n","    /usr/local/bin/import_pb_to_tensorboard\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.6/dist-packages/tensorflow-2.4.0.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","y\n","  Successfully uninstalled tensorflow-2.4.0\n","\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"49dCYlLdcK2D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608315734154,"user_tz":-60,"elapsed":183871,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"2c84de5e-7be2-4154-9b59-efdcaa2e32cc"},"source":["!cd Wav2Lip && pip install -r requirements.txt"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting librosa==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/6e/0eb0de1c9c4e02df0b40e56f258eb79bd957be79b918511a184268e01720/librosa-0.7.0.tar.gz (1.6MB)\n","\u001b[K     |████████████████████████████████| 1.6MB 14.3MB/s \n","\u001b[?25hCollecting numpy==1.17.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/92/57179ed45307ec6179e344231c47da7f3f3da9e2eee5c8ab506bd279ce4e/numpy-1.17.1-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\n","\u001b[K     |████████████████████████████████| 20.4MB 1.4MB/s \n","\u001b[?25hCollecting opencv-contrib-python>=4.2.0.34\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/ec/a66505cb25704066235369c8a1c1ed8d37b21f260f7b66d2cfa3264f0724/opencv_contrib_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (55.7MB)\n","\u001b[K     |████████████████████████████████| 55.7MB 137kB/s \n","\u001b[?25hCollecting opencv-python==4.1.0.25\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/d2/a2dbf83d4553ca6b3701d91d75e42fe50aea97acdc00652dca515749fb5d/opencv_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\n","\u001b[K     |████████████████████████████████| 26.6MB 125kB/s \n","\u001b[?25hCollecting tensorflow==1.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n","\u001b[K     |████████████████████████████████| 83.1MB 51kB/s \n","\u001b[?25hCollecting torch==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/60/f685fb2cfb3088736bafbc9bdbb455327bdc8906b606da9c9a81bae1c81e/torch-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (676.9MB)\n","\u001b[K     |████████████████████████████████| 676.9MB 25kB/s \n","\u001b[?25hCollecting torchvision==0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/45/0f2f3062c92d9cf1d5d7eabd3cae88cea9affbd2b17fb1c043627838cb0a/torchvision-0.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.6MB 48.3MB/s \n","\u001b[?25hCollecting tqdm==4.45.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n","\u001b[?25hRequirement already satisfied: numba==0.48 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (0.48.0)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (2.1.9)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (1.0.0)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (4.4.2)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.0->-r requirements.txt (line 1)) (0.2.2)\n","Collecting soundfile>=0.9.0\n","  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (0.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (0.36.2)\n","Collecting tensorboard<1.13.0,>=1.12.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 45.2MB/s \n","\u001b[?25hCollecting keras-applications>=1.0.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (1.32.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (0.10.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (0.3.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (3.12.4)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->-r requirements.txt (line 5)) (1.1.2)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.3.0->-r requirements.txt (line 7)) (7.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba==0.48->-r requirements.txt (line 9)) (50.3.2)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba==0.48->-r requirements.txt (line 9)) (0.31.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.0->-r requirements.txt (line 1)) (1.14.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 5)) (3.3.3)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 5)) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0->-r requirements.txt (line 5)) (2.10.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.0->-r requirements.txt (line 1)) (2.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 5)) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 5)) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->-r requirements.txt (line 5)) (3.4.0)\n","Building wheels for collected packages: librosa\n","  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for librosa: filename=librosa-0.7.0-cp36-none-any.whl size=1598345 sha256=b3ca5a60d17305eb4bd626fcd0eb3f5ebad146a9ac5487407c91f2995d290101\n","  Stored in directory: /root/.cache/pip/wheels/49/1d/38/c8ad12fcad67569d8e730c3275be5e581bd589558484a0f881\n","Successfully built librosa\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, soundfile, librosa, opencv-contrib-python, opencv-python, tensorboard, keras-applications, tensorflow, torch, torchvision, tqdm\n","  Found existing installation: numpy 1.19.4\n","    Uninstalling numpy-1.19.4:\n","      Successfully uninstalled numpy-1.19.4\n","  Found existing installation: librosa 0.6.3\n","    Uninstalling librosa-0.6.3:\n","      Successfully uninstalled librosa-0.6.3\n","  Found existing installation: opencv-contrib-python 4.1.2.30\n","    Uninstalling opencv-contrib-python-4.1.2.30:\n","      Successfully uninstalled opencv-contrib-python-4.1.2.30\n","  Found existing installation: opencv-python 4.1.2.30\n","    Uninstalling opencv-python-4.1.2.30:\n","      Successfully uninstalled opencv-python-4.1.2.30\n","  Found existing installation: tensorboard 2.4.0\n","    Uninstalling tensorboard-2.4.0:\n","      Successfully uninstalled tensorboard-2.4.0\n","  Found existing installation: torch 1.7.0+cu101\n","    Uninstalling torch-1.7.0+cu101:\n","      Successfully uninstalled torch-1.7.0+cu101\n","  Found existing installation: torchvision 0.8.1+cu101\n","    Uninstalling torchvision-0.8.1+cu101:\n","      Successfully uninstalled torchvision-0.8.1+cu101\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed keras-applications-1.0.8 librosa-0.7.0 numpy-1.17.1 opencv-contrib-python-4.4.0.46 opencv-python-4.1.0.25 soundfile-0.10.3.post1 tensorboard-1.12.2 tensorflow-1.12.0 torch-1.1.0 torchvision-0.3.0 tqdm-4.45.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ey_bN4M6X_95","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608315742279,"user_tz":-60,"elapsed":5537,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"fc6f9cfc-c789-4b25-9855-a47f947e44f5"},"source":["!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""],"execution_count":8,"outputs":[{"output_type":"stream","text":["--2020-12-18 18:22:47--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n","Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n","Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 89843225 (86M) [application/octet-stream]\n","Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n","\n","Wav2Lip/face_detect 100%[===================>]  85.68M  21.6MB/s    in 4.5s    \n","\n","2020-12-18 18:22:52 (19.0 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qdIQfY2Kswcb"},"source":["# Now lets try!"]},{"cell_type":"code","metadata":{"id":"KoVGMtjRZfeR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608315822351,"user_tz":-60,"elapsed":1615,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"f52aeb4a-3c8c-4edd-e19e-e737b960f7fd"},"source":["!cp \"/content/gdrive/My Drive/Colab Notebooks/Deep/input_vid.jpg\" \"/content/gdrive/My Drive/Colab Notebooks/Deep/input_audio.wav\" sample_data/\n","!ls sample_data/"],"execution_count":9,"outputs":[{"output_type":"stream","text":["anscombe.json\t\t      input_audio.wav  mnist_train_small.csv\n","california_housing_test.csv   input_vid.jpg    README.md\n","california_housing_train.csv  mnist_test.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jR5utmDMcSZY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608315971962,"user_tz":-60,"elapsed":75906,"user":{"displayName":"Armel Soubeiga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMQbewkCNdateldfd4eFQpeoOLfW9CmB_BLy8_dg=s64","userId":"17362683622411040754"}},"outputId":"b6d61ea0-7f40-4a94-cd29-47b4b91091cf"},"source":["!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.jpg\" --audio \"../sample_data/input_audio.wav\""],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","Using cuda for inference.\n","Reading video frames...\n","Number of frames available for inference: 1\n","(80, 12342)\n","Length of mel chunks: 3854\n","  0% 0/31 [00:00<?, ?it/s]\n","  0% 0/1 [00:00<?, ?it/s]\u001b[ATHCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=383 error=11 : invalid argument\n","  0% 0/1 [00:00<?, ?it/s]\n","Recovering from OOM error; New batch size: 8\n","\n","  0% 0/1 [00:00<?, ?it/s]\u001b[A\n","100% 1/1 [00:01<00:00,  1.58s/it]\n","Load checkpoint from: checkpoints/wav2lip_gan.pth\n","Model loaded\n","100% 31/31 [00:39<00:00,  1.28s/it]\n","ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n","\u001b[0mInput #0, wav, from '../sample_data/input_audio.wav':\n","  Duration: 00:02:34.27, bitrate: 768 kb/s\n","    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, mono, s16, 768 kb/s\n","Input #1, avi, from 'temp/result.avi':\n","  Metadata:\n","    encoder         : Lavf58.26.101\n","  Duration: 00:02:34.16, start: 0.000000, bitrate: 900 kb/s\n","    Stream #1:0: Video: mpeg4 (Simple Profile) (DIVX / 0x58564944), yuv420p, 640x448 [SAR 1:1 DAR 10:7], 895 kb/s, 25 fps, 25 tbr, 25 tbn, 25 tbc\n","Stream mapping:\n","  Stream #1:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n","  Stream #0:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0m\u001b[0;33m-qscale is ignored, -crf is recommended.\n","\u001b[0m\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0musing SAR=1/1\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mprofile High, level 3.0\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to 'results/result_voice.mp4':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 640x448 [SAR 1:1 DAR 10:7], q=-1--1, 25 fps, 12800 tbn, 25 tbc\n","    Metadata:\n","      encoder         : Lavc57.107.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","    Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s\n","    Metadata:\n","      encoder         : Lavc57.107.100 aac\n","frame= 3854 fps=211 q=-1.0 Lsize=    2571kB time=00:02:34.28 bitrate= 136.5kbits/s speed=8.44x    \n","video:1133kB audio:1323kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 4.723472%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mframe I:16    Avg QP:16.52  size: 52784\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mframe P:999   Avg QP:17.63  size:   200\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mframe B:2839  Avg QP:28.49  size:    40\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mconsecutive B-frames:  1.3%  0.9%  1.9% 95.9%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mmb I  I16..4:  2.0% 85.8% 12.1%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mmb P  I16..4:  0.0%  0.0%  0.0%  P16..4:  1.5%  0.5%  0.3%  0.0%  0.0%    skip:97.7%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  0.7%  0.1%  0.0%  direct: 0.0%  skip:99.2%  L0:43.4% L1:51.6% BI: 5.0%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0m8x8 transform intra:84.3% inter:79.8%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mcoded y,uvDC,uvAC intra: 92.3% 92.8% 75.9% inter: 0.2% 0.4% 0.0%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mi16 v,h,dc,p: 30% 53% 12%  4%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 42% 18% 15%  3%  3%  6%  3%  6%  5%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 35% 20%  8%  3%  5% 10%  7%  7%  5%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mi8c dc,h,v,p: 36% 20% 35%  8%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mref P L0: 69.0%  8.0% 12.8% 10.2%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mref B L0: 81.8% 12.1%  6.1%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mref B L1: 93.8%  6.2%\n","\u001b[1;36m[libx264 @ 0x5638a2f14d00] \u001b[0mkb/s:60.15\n","\u001b[1;36m[aac @ 0x5638a3018000] \u001b[0mQavg: 206.278\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uNOAZvkszEOw"},"source":["# use the \"files\" button on the left to download the result in the Wav2Lip/results/ folder."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d7zgfrQqbKom"},"source":["## **Variations to try**\n"]},{"cell_type":"markdown","metadata":{"id":"0f9A9VDVbZAG"},"source":["1.   Use more padding to include the chin region"]},{"cell_type":"code","metadata":{"id":"45XW4SZAzIz5"},"source":["!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.jpg\" --audio \"../sample_data/input_audio.wav\" --pads 0 20 0 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uo-WnsxfbwTG"},"source":["2.   Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces."]},{"cell_type":"code","metadata":{"id":"xw0xFtZ2bsx8"},"source":["!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.jpg\" --audio \"../sample_data/input_audio.wav\" --resize_factor 2"],"execution_count":null,"outputs":[]}]}